[zh]
[[semantic_similarity]]
    # According to the C-MTEB Benchmark
    # (https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB)
    # the 3 models of different sizes provided BAAI are the best on the
    # embedding task
    # Ref: https://huggingface.co/BAAI/bge-base-zh-v1.5
    # Using this model, it is hard to find two sentence where cos_sim < 0.25.
    model_name = BAAI/bge-base-zh-v1.5
    revision = f03589c
    loader = sentence-transformers
[[sentiment]]
    model_name = IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment
    loader = huggingface
[[toxicity]]
    model_name = alibaba-pai/pai-bert-base-zh-llm-risk-detection
    loader = huggingface
    revision = 0a61c79744cb0173216f015ffecc1ea81c4e0229
[[factual_consistency]]
    model_name = Helsinki-NLP/opus-mt-zh-en
    loader = huggingface
    revision = cf109095479db38d6df799875e34039d4938aaa6
